{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#test_flag_colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/upwork/Martin followers/tomorrowswig_followers\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from pathlib import Path\n",
    "path = Path(\"/content/drive/My Drive/upwork/Martin followers/tomorrowswig_followers\")\n",
    "%cd \"{path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tomorrowswig_followers\n",
    "\n",
    "> An ETL system fully implemented in Jupyter Notebooks in Colab with AWS Lambda as infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "* The code is written and tested in Jupyter notebooks in Colab.\n",
    "* With **nbd_colab** and **pipenv** it's packaged in python code and integrated with github.\n",
    "* With **zappa** it's deployed and scheduled to AWS Lambda\n",
    "\n",
    "Credentials to have:\n",
    "* AWS credentials\n",
    "* Facebook credentials with the access to tomorrowswig instagram business (see cells with `facebook_creds`)\n",
    "* Google Sheets credentials with the access to the `Followers API` worksheet.\n",
    "\n",
    "`TOKEN` is a long-lived facebook API token with 2 months expiration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up https://hallmx.github.io/nbd_colab/:\n",
    "```\n",
    "!pip install -qU nbd-colab zappa pipenv\n",
    "%cd '/content/drive/My Drive/upwork/Martin followers/tomorrowswig_followers'\n",
    "!cp -R '/content/drive/My Drive/.aws' /root/\n",
    "from nbd_colab import *\n",
    "from nbdev import *\n",
    "clone_new_repo()\n",
    "!pipenv shell\n",
    "```\n",
    "Once in pipenv shell:\n",
    "```\n",
    "nbdev_build_lib && pipenv install -e .\n",
    "```\n",
    "Or refer to https://colab.research.google.com/drive/19QxOoqxEiaVq5egE8AY5dwbNlgStO7mN?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grasp how it feels to code in a notebook, refer to https://nbdev.fast.ai/.\n",
    "\n",
    "In short, once you set up **nbd_colab** and activated **pipenv**, simply edit ***.ipynb** files. The code starting with `#export` is generated from them by running `nbdev_build_lib`.\n",
    "\n",
    "To update AWS deployment, execute `zappa update dev ` from pipenv shell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "* 2 events are scheduled - `followers.update` and `ads.create_insights` to query new data. Refer to corresponding notebook to get more details.\n",
    "* All data saved in Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
